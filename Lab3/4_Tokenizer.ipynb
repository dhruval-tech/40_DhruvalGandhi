{"metadata":{"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import csv\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nstopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n","metadata":{"trusted":true},"execution_count":4,"outputs":[],"id":"c43bdde5-af11-4372-aa1b-1e5e17cbe7c8"},{"cell_type":"code","source":"sentences = []\nlabels = []\nwith open(\"bbc-text-small.csv\", 'r') as csvfile:\n    reader = csv.reader(csvfile, delimiter=',')\n    next(reader)\n    for row in reader:\n        labels.append(row[0])\n        sentence = row[1]\n        for word in stopwords:\n            token = \" \" + word + \" \"\n            sentence = sentence.replace(token, \" \")\n            sentence = sentence.replace(\"  \", \" \")\n        sentences.append(sentence)\n\n\nprint(len(sentences))\nprint(sentences[48])\nprint(labels[48])","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"49\nlibya takes $1bn unfrozen funds libya withdrawn $1bn assets us assets previously frozen almost 20 years libyan central bank said. move came us lifted trade ban reward tripoli giving weapons mass destruction vowing compensate lockerbie victims. original size libya s funds $400m central bank told reuters. however withdrawal not mean libya cut ties us added. process opening accounts banks united states central bank s vice president farhat omar ben gadaravice said. previously frozen assets invested various countries believed included equity holdings banks. us ban trade economic activity tripoli - imposed president ronald regan 1986 series us deemed terrorist acts including 1988 lockerbie air crash - suspended april. bankers two country s working unfreeze libya s assets.\nbusiness\n","output_type":"stream"}],"id":"599aae20-2bd9-4b56-ab3f-c18e20efdbcd"},{"cell_type":"code","source":"**Example-2**","metadata":{},"execution_count":null,"outputs":[],"id":"8d894757-1f4a-4031-9da3-bb4dd77cbcd5"},{"cell_type":"code","source":"sentences = [\n    'At DDU, we are Learning ML in semester 7 !!!',\n    'I love ml subject',\n    'Prof Brijesh Bhatt and prof. Hariom Pandya are faculties for the Ml subject',\n    'Do you think ML is amazing?'\n]\n\n##########################################\n\n# Try with words that the tokenizer wasn't fit to\ntest_data = [\n    'i really love CC subject',\n    'Do you think BDA and IP are amazing subjects?'\n]\n\n###############################################\n\n\n#Observations: subject/subjects, ML/mL/ml, i/I  prof/Prof.  !!!","metadata":{"trusted":true},"execution_count":3,"outputs":[],"id":"cc29165a-64eb-47ff-9dfb-c9c3283f74ed"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"d5145600-da84-43f4-b8af-96a57eb1a2ba"}]}